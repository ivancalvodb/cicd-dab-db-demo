# yaml-language-server: $schema=bundle-settings-schema.json
bundle:
  name: awesome-dab-cicd-project

variables:
  dev-catalog:
    description: "Development catalog: dev and test only"
    default: dev_catalog_awesome_company
  
  dev-schema:
    description: "Development schema: dev and test only"
    default: dev_schema_awesome_company

  prod-catalog:
    description: "Production catalog"
    default: prod_catalog_awesome_company

  prod-schema:
    description: "Production schema"
    default: prod_schema_awesome_company 

workspace:
  host: https://adb-984752964297111.11.azuredatabricks.net
  azure_client_id: string # For Databricks on Azure only.
  azure_environment: string # For Databricks on Azure only.
  azure_login_app_id: string # For Databricks on Azure only.
  azure_tenant_id: string # For Databricks on Azure only.
  azure_use_msi: true | false # For Databricks on Azure only.
  azure_workspace_resource_id: string # For Databricks on Azure only.

resources:
  pipelines:
    etl-dlt-sensors-pipeline:
      name: "[${bundle.environment}] Sensors medallion ETL pipeline"
      continuous: false
      channel: "CURRENT"
 
      libraries:
        - notebook:
            path: dlt-pipelines/notebook-etl.sql
      edition: "ADVANCED"

environments:

  dev:
    default: 
      true
    resources:
      pipelines:
        etl-dlt-sensors-pipeline:
          development: true
          photon: false
          catalog: ${var.dev-catalog}
          target: ${var.dev-schema}

          clusters:
            - label: "default"
              num_workers: 1

  prod:

    #workspace:
    #  host: https://random-host.cloud.databricks.com

    resources:
      pipelines:
        etl-dlt-sensors-pipeline:
          development: true #false
          photon: false
          catalog: ${var.prod-catalog}
          target: ${var.prod-schema}

          new_cluster:
            spark_version: 13.1.x-scala2.12
            num_workers: 1
            node_type_id: i3.xlarge