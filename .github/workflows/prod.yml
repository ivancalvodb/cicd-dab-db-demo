name: Main branch PR

on:
  pull_request:
    branches: [ "main" ]

env:
  # For CLI authentication
  DATABRICKS_HOST: ${{secrets.DATABRICKS_HOST}}
  DATABRICKS_TOKEN: ${{secrets.DATABRICKS_TOKEN}}

jobs:

  unit_testing:
    name: Unit testing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run unit tests
        run: python -m pytest tests

  deploy:
    name: Deploy bundle
    runs-on: ubuntu-latest

    # Run the "unit_testing" job first.
    needs:
      - unit_testing

    # Checkout code, setup databricks CLI and then, deploy the bundle using DABs
    steps:
      - uses: actions/checkout@v3
      - uses: databricks/setup-cli@main

      - name: Destroy past bundle files
        continue-on-error: true
        run: databricks bundle destroy --target prod --auto-approve --force-lock 

      - run: databricks bundle deploy --target prod

  pipeline_update:
    name: Run pipeline update
    runs-on: ubuntu-latest

    # Run the "deploy" job before.
    needs:
      - deploy

    steps:
      - uses: actions/checkout@v3
      - uses: databricks/setup-cli@main
      - run: databricks bundle run dlt-sensors-pipeline --refresh-all --target prod
      # in here, we can run all the resources we defined on the databricks.yml